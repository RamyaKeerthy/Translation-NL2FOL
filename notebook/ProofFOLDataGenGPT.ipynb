{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Yjamzfi5Tola"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "hhxAaSAjLEeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECohKZK9Cpcp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"provide_your_api\")"
      ],
      "metadata": {
        "id": "S-0CJHXsz60F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs_prompt = \"\"\"You are an expert who works with theorem provers. Given some context and a question, generate the predicates and the first-order logic formula for contexts and question. Here is an example.\n",
        "------\n",
        "Context:\n",
        "Anne is quiet. Erin is furry. Erin is green. Fiona is furry. Fiona is quiet. Fiona is red. Fiona is rough. Fiona is white. Harry is furry. Harry is quiet. Harry is white. Young people are furry. If Anne is quiet then Anne is red. Young, green people are rough. If someone is green then they are white. If someone is furry and quiet then they are white. If someone is young and white then they are rough. All red people are young.\n",
        "Question:\n",
        "Anne is white.\n",
        "###\n",
        "Predicates:\n",
        "Quiet(x) ::: x is quiet\n",
        "Furry(x) ::: x is furry\n",
        "Green(x) ::: x is green\n",
        "Red(x) ::: x is red\n",
        "Rough(x) ::: x is rough\n",
        "White(x) ::: x is white\n",
        "Young(x) ::: x is young\n",
        "Premises:\n",
        "Quite(Anne) ::: Anne is quiet.\n",
        "Furry(Erin) ::: Erin is furry.\n",
        "Green(Erin) ::: Erin is green.\n",
        "Furry(Fiona) ::: Fiona is furry.\n",
        "Quite(Fiona) ::: Fiona is quiet.\n",
        "Red(Fiona) ::: Fiona is red.\n",
        "Rough(Fiona) ::: Fiona is rough.\n",
        "White(Fiona) ::: Fiona is white.\n",
        "Furry(Harry) ::: Harry is furry.\n",
        "Quite(Harry) ::: Harry is quiet.\n",
        "White(Harry) ::: Harry is white.\n",
        "∀x (Young(x) → Furry(x)) ::: Young people are furry.\n",
        "Quite(Anne) → ¬Red(Anne) ::: If Anne is quiet then Anne is not red.\n",
        "∀x (Young(x) → Rough(x)) ::: Young, green people are rough.\n",
        "∀x (Green(x) → Rough(x)) ::: Young, green people are rough.\n",
        "∀x (Green(x) → White(x)) ::: If someone is green then they are white.\n",
        "∀x (Furry(x) ∧ Quite(x) → ¬White(x)) ::: If someone is furry and quiet then they are not white.\n",
        "∀x (Young(x) ∧ White(x) → Rough(x)) ::: If someone is young and white then they are rough.\n",
        "∀x (Red(x) → Young(x)) ::: All red people are young.\n",
        "Conclusion:\n",
        "White(Anne) ::: Anne is white.\n",
        "------\n",
        "Context:\n",
        "[[PROBLEM]]\n",
        "Question:\n",
        "[[QUESTION]]\n",
        "###\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6g_4rWtWFFzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_json('proof_train_sampled_15000.json')"
      ],
      "metadata": {
        "id": "zQZysA9CFLcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Generate"
      ],
      "metadata": {
        "id": "jQAgF2jE0VKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create JSONL file for Chat Completions API\n",
        "def create_jsonl_for_chat(df, output_file):\n",
        "    with open(output_file, 'w') as file:\n",
        "        for _, row in df.iterrows():\n",
        "            context = row['Context'].strip()\n",
        "            question = row['Question'].strip()\n",
        "            full_prompt = fs_prompt.replace(\"[[PROBLEM]]\", context).replace(\"[[QUESTION]]\",question)\n",
        "            json_line = {\n",
        "                \"custom_id\": f\"request-{row['id']}\",\n",
        "                \"method\": \"POST\",\n",
        "                \"url\": \"/v1/chat/completions\",\n",
        "                \"body\": {\n",
        "                    \"model\": \"gpt-4o\",\n",
        "                    \"messages\": [{\"role\": \"user\", \"content\": full_prompt}],\n",
        "                    \"max_tokens\": 1000\n",
        "                }\n",
        "            }\n",
        "            file.write(json.dumps(json_line) + '\\n')\n",
        "\n",
        "# Usage\n",
        "create_jsonl_for_chat(df, 'proof_train_sampled_15000.json')\n"
      ],
      "metadata": {
        "id": "hGyaOiZMx5Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input_file = client.files.create(\n",
        "  file=open(\"/content/folio_train_1001.jsonl\", \"rb\"),\n",
        "  purpose=\"batch\"\n",
        ")\n",
        "batch_input_file_id = batch_input_file.id"
      ],
      "metadata": {
        "id": "Bt-C0zzjLbHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.batches.create(\n",
        "    input_file_id=batch_input_file_id,\n",
        "    endpoint=\"/v1/chat/completions\",\n",
        "    completion_window=\"24h\",\n",
        "    metadata={\n",
        "      \"description\": \"folio fol generation 1001 records\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "7OxX3ELbLhQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.batches.retrieve(\"batch_id\")"
      ],
      "metadata": {
        "id": "WCimUiJEL9Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = client.files.content(\"output_file_id\")"
      ],
      "metadata": {
        "id": "-24VY5d2MDe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_bytes = content.read()\n",
        "with open(\"save_file.jsonl\", \"wb\") as file:\n",
        "    file.write(content_bytes)"
      ],
      "metadata": {
        "id": "9Uy8H0kcUR5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse GPT output"
      ],
      "metadata": {
        "id": "TnAy8_Fl8qVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_op = {}\n",
        "# lines = content.strip().split('\\n')\n",
        "with open('batch_FBKUJMbX3iZcL4GS6kPVQnsg_output.jsonl', 'r') as file:\n",
        "  # Parse each line as JSON\n",
        "  for line in file:\n",
        "      data = json.loads(line)\n",
        "      # Now 'data' contains the parsed JSON object for each line\n",
        "      gpt_op[data['custom_id']] = data['response']['body']['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "5NBX2kujNjpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_logic = pd.DataFrame(list(gpt_op.items()), columns=['id', 'logic_program'])\n",
        "df_logic['id'] = df_logic['id'].apply(lambda x: x.split(\"request-\")[-1].strip())"
      ],
      "metadata": {
        "id": "01OhVV1s6wYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_train.merge(df_logic, on='id')"
      ],
      "metadata": {
        "id": "HngZX69vAPSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.to_json(\"proof_train_logic.json\", orient=\"records\", indent=4)"
      ],
      "metadata": {
        "id": "0Kwpr1uwAnnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass this to the tool to extract valid results."
      ],
      "metadata": {
        "id": "ZJ0H6jZe07fu"
      }
    }
  ]
}